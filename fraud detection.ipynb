{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Optional for Running on Local Machine\n",
        "Run the command below to install the packages according to the configuration file requirements.txt."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "shellscript"
        }
      },
      "outputs": [],
      "source": [
        "pip install -r requirements.txt"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# About the data\n",
        "The data for this project can be found [here](https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud). This dataset contains the real bank transactions made by European cardholders in the year 2013. As a security concern, the actual variables are not being shared but — they have been transformed versions of PCA. As a result, we can find 29 feature columns and 1 final class column."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![Data Snapshot](./images/Data%20Snapshot.webp)  "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Importing Necessary Libraries\n",
        "It is a good practice to import all the necessary libraries in one place — so that we can modify them quickly.\n",
        "\n",
        "For this credit card data, the features that we have in the dataset are the transformed version of PCA, so we will not need to perform the feature selection again. Otherwise, it is recommended to use RFE, RFECV, SelectKBest and VIF score to find the best features for your model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Packages related to general operating system & warnings\n",
        "import os \n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "#Packages related to data importing, manipulation, exploratory data #analysis, data understanding\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pandas import Series, DataFrame\n",
        "from termcolor import colored as cl # text customization\n",
        "#Packages related to data visualizaiton\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "#Setting plot sizes and type of plot\n",
        "plt.rc(\"font\", size=14)\n",
        "plt.rcParams['axes.grid'] = True\n",
        "plt.figure(figsize=(6,3))\n",
        "plt.gray()\n",
        "from matplotlib.backends.backend_pdf import PdfPages\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn import metrics\n",
        "from sklearn.impute import MissingIndicator, SimpleImputer\n",
        "from sklearn.preprocessing import  PolynomialFeatures, KBinsDiscretizer, FunctionTransformer\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler, MaxAbsScaler\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, LabelBinarizer, OrdinalEncoder\n",
        "import statsmodels.formula.api as smf\n",
        "import statsmodels.tsa as tsa\n",
        "from sklearn.linear_model import LogisticRegression, LinearRegression, ElasticNet, Lasso, Ridge\n",
        "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
        "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor, export_graphviz\n",
        "from sklearn.ensemble import BaggingClassifier, BaggingRegressor,RandomForestClassifier,RandomForestRegressor\n",
        "from sklearn.ensemble import GradientBoostingClassifier,GradientBoostingRegressor, AdaBoostClassifier, AdaBoostRegressor \n",
        "from sklearn.svm import LinearSVC, LinearSVR, SVC, SVR\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Importing Dataset\n",
        "Importing the dataset is pretty much simple. You can use pandas module in python to import it.\n",
        "\n",
        "Run the below command to import your data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data=pd.read_csv(\"creditcard.csv\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Processing & Understanding\n",
        "The one main thing you will notice about this data is that — the dataset is imbalanced towards a feature. Which seems pretty valid for such kind of data. Because today many banks have adopted different security mechanisms — so it is harder for hackers to make such moves.\n",
        "\n",
        "Still, sometimes when there is some vulnerability in the system — the chance of such activities can increase.\n",
        "\n",
        "That’s why we can see the majority of transactions belongs to our datasets are normal and only a few percentages of transactions are fraudulent.\n",
        "\n",
        "Let’s check the transaction distribution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "Total_transactions = len(data)\n",
        "normal = len(data[data.Class == 0])\n",
        "fraudulent = len(data[data.Class == 1])\n",
        "fraud_percentage = round(fraudulent/normal*100, 2)\n",
        "print(cl('Total number of Trnsactions are {}'.format(Total_transactions), attrs = ['bold']))\n",
        "print(cl('Number of Normal Transactions are {}'.format(normal), attrs = ['bold']))\n",
        "print(cl('Number of fraudulent Transactions are {}'.format(fraudulent), attrs = ['bold']))\n",
        "print(cl('Percentage of fraud Transactions is {}'.format(fraud_percentage), attrs = ['bold']))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Only 0.17% of transactions are fraudulent.\n",
        "\n",
        "We can also check for null values using the following line of code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data.info()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As per the count per column, we have no null values. Also, feature selection is not the case for this use case. Anyway, you can try applying feature selection mechanisms to check if the results are optimised.\n",
        "\n",
        "I have observed in our data 28 features are transformed versions of PCA but the Amount is the original one. And, while checking the minimum and maximum is in the amount — I found the difference is huge that can deviate our result."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "min(data.Amount), max(data.Amount)\n",
        "#(0.0, 25691.16)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this case, it is a good practice to scale this variable. We can use a standard scaler to make it fix."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sc = StandardScaler()\n",
        "amount = data['Amount'].values\n",
        "data['Amount'] = sc.fit_transform(amount.reshape(-1, 1)) # type: ignore"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We have one more variable which is the time which can be an external deciding factor — but in our modelling process, we can drop it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data.drop(['Time'], axis=1, inplace=True)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can also check for any duplicate transactions. Before removing any duplicate transaction, we are having 284807 transactions in our data. Let’s remove the duplicate and observe the changes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data.shape\n",
        "#(284807, 30)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Run the below line of code to remove any duplicates."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data.drop_duplicates(inplace=True)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let’s now check the count again."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data.shape\n",
        "#(275663, 30)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "So, we were having around ~9000 duplicate transactions.\n",
        "\n",
        "Here we go!! We now have properly scaled data with no duplicate, no missing. Let’s now split it for our model building."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Train & Test Split\n",
        "Before splitting train & test — we need to define dependent and independent variables. The dependent variable is also known as X and the independent variable is known as **y**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X = data.drop('Class', axis = 1).values\n",
        "y = data['Class'].values"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, let split our train and test data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 1)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "That’s it. We now have two different data set — Train data we will be used for training our model and the data which is unseen will be used for testing."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Model Building\n",
        "We will be trying different machine learning models one by one. Defining models are much easier. A single line of code can define our model. And, in the same way, a single line of code can fit the model on our data.\n",
        "\n",
        "We can also tune these models by selecting different optimized parameters. But, if the accuracy is better even with less parameter tuning then — no need to make it complex."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## *Decision Tree*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "DT = DecisionTreeClassifier(max_depth = 4, criterion = 'entropy')\n",
        "DT.fit(X_train, y_train)\n",
        "dt_yhat = DT.predict(X_test)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let’s check the accuracy of our decision tree model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print('Accuracy score of the Decision Tree model is {}'.format(accuracy_score(y_test, dt_yhat)))\n",
        "#Accuracy score of the Decision Tree model is 0.9991583957281328"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Checking F1-Score for the decision tree model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print('F1 score of the Decision Tree model is {}'.format(f1_score(y_test, dt_yhat)))\n",
        "#F1 score of the Decision Tree model is 0.7542372881355933"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Checking the confusion matrix:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "confusion_matrix(y_test, dt_yhat, labels = [0, 1])\n",
        "#array([[68769,    19],\n",
        "#       [   39,    89]], dtype=int64)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here, the first row represents positive and the second row represents negative. So, we have 68769 as true positive and 19 are false positive. That says, out of 68769+19=68788, we have 68769 that are successfully classified as a normal transaction and 19 were falsely classified as normal — but they were fraudulent.\n",
        "\n",
        "Let’s now try different models and check their performance."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## *K-Nearest Neighbors*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "n = 7\n",
        "KNN = KNeighborsClassifier(n_neighbors = n)\n",
        "KNN.fit(X_train, y_train)\n",
        "knn_yhat = KNN.predict(X_test)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let’s check the accuracy of our K-Nearest Neighbors model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print('Accuracy score of the K-Nearest Neighbors model is {}'.format(accuracy_score(y_test, knn_yhat)))\n",
        "#Accuracy score of the K-Nearest Neighbors model is 0.999288989494457"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Checking F1-Score for the K-Nearest Neighbors model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print('F1 score of the K-Nearest Neighbors model is {}'.format(f1_score(y_test, knn_yhat)))\n",
        "#F1 score of the K-Nearest Neighbors model is 0.7949790794979079"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## *Logistic Regression*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "lr = LogisticRegression()\n",
        "lr.fit(X_train, y_train)\n",
        "lr_yhat = lr.predict(X_test)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let’s check the accuracy of our Logistic Regression model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print('Accuracy score of the Logistic Regression model is {}'.format(accuracy_score(y_test, lr_yhat)))\n",
        "#Accuracy score of the Logistic Regression model is 0.9989552498694062"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Checking F1-Score for the Logistic Regression model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print('F1 score of the Logistic Regression model is {}'.format(f1_score(y_test, lr_yhat)))\n",
        "#F1 score of the Logistic Regression model is 0.6666666666666666"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## *Support Vector Machines*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "svm = SVC()\n",
        "svm.fit(X_train, y_train)\n",
        "svm_yhat = svm.predict(X_test)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let’s check the accuracy of our Support Vector Machines model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print('Accuracy score of the Support Vector Machines model is {}'.format(accuracy_score(y_test, svm_yhat)))\n",
        "#Accuracy score of the Support Vector Machines model is 0.999318010331418"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Checking F1-Score for the Support Vector Machines model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print('F1 score of the Support Vector Machines model is {}'.format(f1_score(y_test, svm_yhat)))\n",
        "#F1 score of the Support Vector Machines model is 0.7813953488372093"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## *Random Forest*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "rf = RandomForestClassifier(max_depth = 4)\n",
        "rf.fit(X_train, y_train)\n",
        "rf_yhat = rf.predict(X_test)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let’s check the accuracy of our Random Forest model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print('Accuracy score of the Random Forest model is {}'.format(accuracy_score(y_test, rf_yhat)))\n",
        "#Accuracy score of the Random Forest model is 0.9991729061466132"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Checking F1-Score for the Random Forest model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print('F1 score of the Random Forest model is {}'.format(f1_score(y_test, rf_yhat)))\n",
        "#F1 score of the Random Forest model is 0.7397260273972602"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## *XGBoost*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "xgb = XGBClassifier(max_depth = 4)\n",
        "xgb.fit(X_train, y_train)\n",
        "xgb_yhat = xgb.predict(X_test)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let’s check the accuracy of our XGBoost model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print('Accuracy score of the XGBoost model is {}'.format(accuracy_score(y_test, xgb_yhat)))\n",
        "#Accuracy score of the XGBoost model is 0.999506645771664"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Checking F1-Score for the XGBoost model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print('F1 score of the XGBoost model is {}'.format(f1_score(y_test, xgb_yhat)))\n",
        "#F1 score of the XGBoost model is 0.8495575221238937"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Conclusion"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Well, congratulation!! We just received 99.95% accuracy in our credit card fraud detection. This number should not be surprising as our data was balanced towards one class. The good thing that we have noticed from the confusion matrix is that — our model is not overfitted.\n",
        "\n",
        "Finally, based on our accuracy score — XGBoost is the winner for our case. The only catch here is the data that we have received for model training. The data features are the transformed version of PCA. If the actual features follow a similar pattern then we are doing great!!"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.1"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "dae50b35cf400aa3d2b37210f42c2ac5eecfcaf67f8f41e2a535d6bb67f4df64"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
